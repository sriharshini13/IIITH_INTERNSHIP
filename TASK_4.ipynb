{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP49nRwteWhdky/CXNKIxT1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sriharshini13/IIITH_INTERNSHIP/blob/main/TASK_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìò YOLOv8 Custom Object Detection ‚Äì Full Project Guide\n",
        "\n",
        "**Objective:** Detect a custom object (e.g., bike) by creating your own dataset from a YouTube video, annotating it, training YOLOv8, and testing the results.\n",
        "\n",
        "---\n",
        "\n",
        "## üß± STEP 1: Project Folder Setup\n",
        "\n",
        "### Create a Project Folder\n",
        "Create a new folder called:\n",
        "`yolov8_bike_detection`\n",
        "\n",
        "### Open it in VS Code\n",
        "Right-click the newly created folder and select \"Open with Code\".\n",
        "\n",
        "---\n",
        "\n",
        "## üêç STEP 2: Python Virtual Environment Setup\n",
        "\n",
        "### Open Terminal in VS Code\n",
        "Go to `Terminal` > `New Terminal` in VS Code.\n",
        "\n",
        "### Create and Activate a Virtual Environment\n",
        "```bash\n",
        "python -m venv yolovenv\n",
        "yolovenv\\Scripts\\activate   # For Windows\n",
        "(You should see (yolovenv) at the beginning of your terminal prompt, indicating the environment is active.)\n",
        "\n",
        "Install Required Packages\n",
        "Ensure your yolovenv environment is active, then run:\n",
        "\n",
        "Bash\n",
        "\n",
        "pip install ultralytics roboflow opencv-python yt-dlp\n"
      ],
      "metadata": {
        "id": "9-FXziHaTFxs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **STEP 3: Download and Extract Frames from YouTube Video**\n",
        "\n",
        "Create a folder to store your video\n",
        "\n",
        "    mkdir video\n",
        "    cd video\n",
        "\n",
        "Download the video\n",
        "Bash\n",
        "\n",
        "    yt-dlp -f best -o \"myvideo.%(ext)s\" [https://www.youtube.com/watch?v=VIDEO_ID](https://www.youtube.com/watch?v=VIDEO_ID)\n",
        "(This will download the best quality video and name it myvideo.mp4 or myvideo.webm based on the format.)\n",
        "\n",
        "(Optional) Rename the file if needed\n",
        "If the downloaded file is myvideo.webm and you prefer myvideo.mp4:\n",
        "\n",
        "Bash\n",
        "\n",
        "    ren myvideo.webm myvideo.mp4\n",
        "Go back to the main project folder and extract frames\n",
        "Bash\n",
        "\n",
        "    cd ..  # Go back to yolov8_bike_detection\n",
        "    mkdir frames\n",
        "    ffmpeg -i video/myvideo.mp4 -vf fps=1 frames/frame_%04d.jpg\n",
        "(This will extract one frame per second from your video and save them as JPG images in the frames folder.)\n",
        "\n",
        " **STEP 4: Annotate Images Using Roboflow**\n",
        "\n",
        "1. Go to Roboflow\n",
        "Navigate to: https://app.roboflow.com\\\n",
        "Sign up for a free account or log in.\n",
        "\n",
        "2. Create a New Project\n",
        "Click Create New Project.\n",
        "\n",
        "3. Set Project Type: Object Detection (Bounding Box).\n",
        "\n",
        "Give it a Name: e.g., bike_detection.\n",
        "\n",
        "4. Define Class Names: e.g., bike (add more if you have other objects).\n",
        "\n",
        "5. Upload Images\n",
        "Click Upload.\n",
        "\n",
        "6. Select \"Local\" or \"Folder\" and upload all images from the frames/ folder you created in Step 3.\n",
        "\n",
        "7. Annotate Images\n",
        "Go to the Annotate section.\n",
        "\n",
        "8. Manually draw tight bounding boxes around all instances of your objects (e.g., bikes) in each image.\n",
        "\n",
        "9. Ensure all images are thoroughly annotated.\n",
        "\n",
        "10. Generate Dataset\n",
        "Once annotation is complete, click the \"Generate\" button (usually at the bottom-left of the annotation interface).\n",
        "\n",
        "11. Choose Generate New Version.\n",
        "\n",
        "Under Preprocessing, select Resize to 640x640 (Stretch).\n",
        "\n",
        "(Optional, but recommended for small datasets) Under Augmentation, apply transformations like Flip (Horizontal), Rotate (up to 15 degrees), Brightness (random 0-15%) to increase dataset variety.\n",
        "\n",
        "12. Click Generate.\n",
        "\n",
        "13. Download the ZIP file\n",
        "After the dataset is generated, click Export.\n",
        "\n",
        "14. Choose export format: YOLOv8 PyTorch.\n",
        "\n",
        "15. Select Download zip to computer.\n",
        "---\n",
        "\n",
        "**STEP 5: Organize the Dataset Locally**\n",
        "\n",
        "Unzip the Roboflow ZIP file into your project folder\n",
        "Move the downloaded .zip file into your yolov8_bike_detection folder.\n",
        "\n",
        "Right-click the .zip file and select \"Extract All...\" to unzip it.\n",
        "\n",
        "This will create a new folder (e.g., bike_detection-1) inside your yolov8_bike_detection project. You can rename this folder to dataset for simplicity.\n",
        "\n",
        "Verify and Adjust data.yaml\n",
        "Navigate into the dataset/ folder (or whatever you named the extracted folder).\n",
        "\n",
        "Open the data.yaml file located there.\n",
        "\n",
        "Ensure the paths are relative to the dataset folder as follows:\n",
        "\n",
        "YAML\n",
        "\n",
        "    # Path to the dataset root folder (e.g., 'dataset')\n",
        "    path: .\n",
        "\n",
        "    # Train and validation image/label paths, relative to 'path'\n",
        "    train: train/images\n",
        "    val: valid/images\n",
        "    test: test/images # Keep this line if Roboflow created a test set, otherwise delete it\n",
        "\n",
        "    # Number of classes\n",
        "    nc: 1 # Or the total number of classes you defined\n",
        "\n",
        "    # Class names\n",
        "    names: ['bike'] # Or your list of class names, e.g., ['apple', 'banana', 'orange']\n",
        "Save the data.yaml file.\n",
        "---\n",
        "**STEP 6: Train YOLOv8 on Custom Dataset\n",
        "Run YOLOv8 Training**\n",
        "\n",
        "Ensure your yolovenv virtual environment is active in the VS Code terminal.\n",
        "\n",
        "Bash\n",
        "\n",
        "    yolo task=detect mode=train model=yolov8n.pt data=dataset/data.yaml epochs=30 imgsz=640\n",
        "    model: You can use yolov8n.pt (nano, smallest, fastest), yolov8s.pt (small), yolov8m.pt (medium), etc., depending on your desired accuracy and available training time. yolov8n.pt is good for CPU.\n",
        "\n",
        "epochs: Number of training iterations (e.g., 30). You might need more for better accuracy.\n",
        "\n",
        "imgsz: Input image size (e.g., 640x640).\n",
        "\n",
        "Output Directory\n",
        "The training output (trained model, plots, metrics) is saved to:\n",
        "yolov8_bike_detection/runs/detect/train/\n",
        "\n",
        "Inside, you'll find:\n",
        "\n",
        "weights/best.pt ‚Üí Your best trained model weights.\n",
        "\n",
        "Training plots and metrics (results.png, etc.).\n",
        "\n",
        "---\n",
        "**STEP 7: Run Inference on New Images**\n",
        "Place test image in project folder\n",
        "Create a new folder test_images in yolov8_bike_detection. Place an image or video (e.g., my_bike_test.jpg or my_bike_test.mp4) that your model has not seen during training here.\n",
        "\n",
        "Run Inference Using Trained Model\n",
        "Ensure your yolovenv virtual environment is active.\n",
        "\n",
        "Bash\n",
        "\n",
        "    yolo task=detect mode=predict model=runs/detect/train/weights/best.pt source=test_images/my_bike_test.jpg save=True\n",
        "IMPORTANT: Replace test_images/my_bike_test.jpg with the actual path and filename of your test image or video.\n",
        "\n",
        "save=True will save the output image/video with bounding boxes.\n",
        "\n",
        "Check Output\n",
        "Annotated images/videos with detections will be saved in:\n",
        "yolov8_bike_detection/runs/detect/predict/\n",
        "(Subsequent runs will create predict2, predict3, etc.)\n",
        "\n",
        "üìÅ Final Project Folder Structure (Example)\n",
        "\n",
        "    yolov8_bike_detection/\n",
        "    ‚îú‚îÄ‚îÄ yolovenv/                  # Python virtual environment\n",
        "    ‚îú‚îÄ‚îÄ video/\n",
        "    ‚îÇ   ‚îî‚îÄ‚îÄ myvideo.mp4            # Your downloaded YouTube video\n",
        "    ‚îú‚îÄ‚îÄ frames/\n",
        "    ‚îÇ   ‚îî‚îÄ‚îÄ frame_0001.jpg         # Extracted video frames\n",
        "    ‚îÇ   ‚îî‚îÄ‚îÄ frame_0002.jpg\n",
        "    ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
        "    ‚îú‚îÄ‚îÄ dataset/                   # Your annotated dataset from Roboflow\n",
        "    ‚îÇ   ‚îú‚îÄ‚îÄ train/\n",
        "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ images/\n",
        "    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ labels/\n",
        "    ‚îÇ   ‚îú‚îÄ‚îÄ valid/\n",
        "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ images/\n",
        "    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ labels/\n",
        "    ‚îÇ   ‚îú‚îÄ‚îÄ test/\n",
        "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ images/\n",
        "    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ labels/\n",
        "    ‚îÇ   ‚îî‚îÄ‚îÄ data.yaml              # Dataset configuration file\n",
        "    ‚îú‚îÄ‚îÄ test_images/               # Folder for new images/videos to test\n",
        "    ‚îÇ   ‚îî‚îÄ‚îÄ my_bike_test.jpg  \n",
        "    ‚îú‚îÄ‚îÄ runs/                      # Directory for training and inference outputs\n",
        "    ‚îÇ   ‚îî‚îÄ‚îÄ detect/\n",
        "    ‚îÇ       ‚îú‚îÄ‚îÄ train/             # Training results\n",
        "    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ weights/\n",
        "    ‚îÇ       ‚îÇ       ‚îî‚îÄ‚îÄ best.pt    # Your trained model weights\n",
        "    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ results.png\n",
        "    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
        "    ‚îÇ       ‚îî‚îÄ‚îÄ predict/           # Inference results\n",
        "    ‚îÇ           ‚îî‚îÄ‚îÄ my_bike_test.jpg # Annotated test image\n",
        "    ‚îÇ           ‚îî‚îÄ‚îÄ ...\n",
        "    ‚îî‚îÄ‚îÄ .gitignore                 # (Optional) For Git users\n",
        "    ‚îî‚îÄ‚îÄ README.md                  # (Optional) Project description\n"
      ],
      "metadata": {
        "id": "qqxsaz9bTlaN"
      }
    }
  ]
}